experiment_name: gptneo1B_train
train_path: ../finetune_data/v2_finetune.jsonl
eval_path: ../finetune_data/v2_finetune_valid.jsonl
lr: 5.0e-5 
warmup_steps: 1_000
weight_decay: 0.01
gradient_clipping: 1.0
train_steps: 10_000
logging_steps: 500
eval_steps: 1_000
save_steps: 5_000
batch_size: 6
accum_steps: 4
model_name: "EleutherAI/gpt-neo-1.3B"
max_length: 450
