batch_size: 10
before_example: "\nLean mathlib version:\n"
after_example: "\nTranslate the Lean mathlib version to a natural language version: \""
in_key: "formal_statement"
out_key: "gpt_nl_statement"
ref_key: "nl_statement"
save_dir: "results/toy_codex_12shot_informalize"
save_file: "out.jsonl"
few_shot_prompt_path: "prompts/12shot_informalize.txt"
data_path: "model_input.jsonl"
stop: "\""
max_tokens: 275
split: "test"

